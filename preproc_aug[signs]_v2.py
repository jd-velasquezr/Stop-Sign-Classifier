# -*- coding: utf-8 -*-
"""PreProc_Aug[SIGNS]_V2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WfgNeS_OKfktB1VQd3CSwHWsGZoY1Fw1
"""

# This code contains the logic implemented to filter and extract the red color
# from the images of the stop signs. Besides, this code can increase the number
# of images in order to augment the number of data in the dataset to train.

!pip install Augmentor
import Augmentor
import cv2
import numpy as np
from matplotlib import pyplot as plt
from google.colab.patches import cv2_imshow
from google.colab import drive
import os
import re
from tqdm import tqdm

drive.mount('/content/drive')
# Ruta del Dataset de entrada.
path = '/content/drive/MyDrive/Signs/'

#augm_sign = Augmentor.Pipeline("/content/drive/MyDrive/Signs/stop/")

def apply_sharpening_filter(image_path, kernel_size=(3, 3), strength=1.4):
    # Image Reading
    img = cv2.imread(image_path)

    # Converts iamge from BGR to RGB
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Increases saturation and contrast
    img_rgb = cv2.convertScaleAbs(img_rgb, alpha=1.3, beta=0)
    hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)
    hsv[:, :, 1] = np.clip(hsv[:, :, 1] * 1.5, 0, 255)
    img_enhanced = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)

    # Creates a focus kernel.
    kernel = np.array([[-1, -1, -1],
                       [-1,  9, -1],
                       [-1, -1, -1]])

    # Applies a convolution filter.
    sharpened_img = cv2.filter2D(img, -1, kernel * strength)

    return sharpened_img


def filter_red_color(image_path,i):
    # Reads the image.
    img = apply_sharpening_filter(image_path, kernel_size=(3, 3), strength=1.7)
    #img = cv2.imread(image_path)
    # Converts iamge from BGR to RGB
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Defines the red color ranges of HSV space.
    lower_red = np.array([0, 100, 20])
    upper_red = np.array([10, 255, 255])

    lower_red2 = np.array([160,100,20])
    upper_red2 = np.array([179,255,255])

    # Converts the image to HSV space.
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)

    lower_mask = cv2.inRange(hsv, lower_red, upper_red)
    upper_mask = cv2.inRange(hsv, lower_red2, upper_red2)

    full_mask = lower_mask + upper_mask;

    # FIlters the red colours.

    # Applies the mask to the original image.
    result = cv2.bitwise_and(img_rgb, img_rgb, mask=full_mask)

    # Muestra la imagen original y la imagen filtrada
    plt.subplot(1, 2, 1)
    plt.imshow(img_rgb)
    plt.title('Imagen Original')

    plt.subplot(1, 2, 2)
    plt.imshow(result)
    plt.title('Solo Color Rojo')

    plt.show()
    result = cv2.resize(result, (256,256), interpolation = cv2.INTER_AREA)
    cv2.imwrite(f'/content/drive/MyDrive/Signs_Preproc/stop/image_{i}', result)


def augmentation(dir_in, n_samples):

  p = Augmentor.Pipeline(dir_in,output_directory=dir_in)


  p.skew_left_right(probability=0.35)

  p.skew_corner(probability=0.35)


  p.shear(probability=0.15, max_shear_left = 25, max_shear_right = 25)

  num_of_samples = int(750)

  # Now we can sample from the pipeline:
  p.sample(num_of_samples)

"""**AUMENTO DE NOT STOP**"""

augmentation("/content/drive/MyDrive/Signs/not_stop",100)

"""**AUMENTO DE STOP**"""

augmentation("/content/drive/MyDrive/Signs/stop",100)

"""**IMAGE COMPARISON WITH AND WITHOUT RED FILTERING ON NOT STOP SIGN IMAGES**"""

contenido= os.listdir("/content/drive/MyDrive/Signs/not_stop")
r= re.compile("\.(jpg|png|JPG|jpeg)", re.IGNORECASE)
coments= list(filter(r.search,contenido))
A= os.path.join("/content/drive/MyDrive/Signs/not_stop/"+coments[0])
for i in tqdm(coments):
# Images path declaration
  path=os.path.join("/content/drive/MyDrive/Signs/not_stop/"+i)
  result = filter_red_color(path,i)

"""**IMAGE GENERATION WITH AND WITHOUT RED FILTERING ON STOP SIGNS IMAGES**"""

contenido= os.listdir("/content/drive/MyDrive/Signs/stop")
r= re.compile("\.(jpg|png|JPG|jpeg)", re.IGNORECASE)
coments= list(filter(r.search,contenido))
A= os.path.join("/content/drive/MyDrive/Signs/stop/"+coments[0])
for i in tqdm(coments):
# Images path declaration
  path=os.path.join("/content/drive/MyDrive/Signs/stop/"+i)
  result = filter_red_color(path,i)

import os
from PIL import Image

def contar_imagenes_en_carpeta(ruta_carpeta):
    # Lists all images in folder
    archivos = os.listdir(ruta_carpeta)

    # Filters all files with the given extension. (png, jpg, jpeg, gif and bmp)
    imagenes = [archivo for archivo in archivos if archivo.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]

    # Counts number of images
    cantidad_imagenes = len(imagenes)

    return cantidad_imagenes

# Filepath of folder to analyze
ruta_carpeta = '/content/drive/MyDrive/Signs_Preproc/not_stop/'

# Calls the function that counts the number of images in file.
cantidad_imagenes = contar_imagenes_en_carpeta(ruta_carpeta)

print(f'La carpeta "Stop" contiene {cantidad_imagenes} imágenes.')

cantidad_imagenes = contar_imagenes_en_carpeta('/content/drive/MyDrive/Signs_Preproc/not_stop/')

print(f'La carpeta "Stop" contiene {cantidad_imagenes} imágenes.')

"""**ANOTHER AUGMENTATIONS**"""

def augmentation(dir_in, n_samples):

  p = Augmentor.Pipeline(dir_in,output_directory=dir_in)


  p.skew_left_right(probability=0.15)

  p.skew_corner(probability=0.15)


  p.shear(probability=0.15, max_shear_left = 25, max_shear_right = 25)

  p.rotate(probability = 0.30, max_left_rotation = 25, max_right_rotation = 25)
  p.rotate90(probability = 0.15)
  p.rotate180(probability = 0.05)
  p.rotate_random_90(probability = 0.05)

  num_of_samples = int(n_samples)

  # Now we can sample from the pipeline:
  p.sample(num_of_samples)

len_stop = contar_imagenes_en_carpeta('/content/drive/MyDrive/Signs_Preproc/stop/')
len_not = contar_imagenes_en_carpeta('/content/drive/MyDrive/Signs_Preproc/not_stop/')

print(len_not_stop)

augmentation('/content/drive/MyDrive/Signs_Preproc/stop/', 2000)
augmentation('/content/drive/MyDrive/Signs_Preproc/not_stop/', 1500)